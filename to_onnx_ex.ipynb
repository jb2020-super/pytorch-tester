{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some standard imports\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super Resolution model definition in PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "        init.zeros_(self.conv4.bias)  \n",
    "\n",
    "# Create the super-resolution model by using the above model definition.\n",
    "model = SuperResolutionNet(upscale_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "conv1.weight \t torch.Size([64, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([64])\n",
      "conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "conv2.bias \t torch.Size([64])\n",
      "conv3.weight \t torch.Size([32, 64, 3, 3])\n",
      "conv3.bias \t torch.Size([32])\n",
      "conv4.weight \t torch.Size([9, 32, 3, 3])\n",
      "conv4.bias \t torch.Size([9])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def print_state_dict(state_dict):    \n",
    "    print(len(state_dict))\n",
    "    for layer in state_dict:\n",
    "        print(layer, '\\t', state_dict[layer].shape)\n",
    "    print(state_dict['conv4.bias'])\n",
    "print_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "conv1.weight \t torch.Size([64, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([64])\n",
      "conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "conv2.bias \t torch.Size([64])\n",
      "conv3.weight \t torch.Size([32, 64, 3, 3])\n",
      "conv3.bias \t torch.Size([32])\n",
      "conv4.weight \t torch.Size([9, 32, 3, 3])\n",
      "conv4.bias \t torch.Size([9])\n",
      "tensor([-0.0151, -0.0191, -0.0362, -0.0224,  0.0548,  0.0113,  0.0529,  0.0258,\n",
      "        -0.0180])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperResolutionNet(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pixel_shuffle): PixelShuffle(upscale_factor=3)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model weights\n",
    "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
    "\n",
    "model.load_state_dict(model_zoo.load_url(model_url))\n",
    "\n",
    "print_state_dict(model.state_dict())\n",
    "# set the model to inference mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "x = torch.randn(1, 1, 224, 224, requires_grad=True)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input \n",
    "                  \"D:\\\\super_resolution.onnx\",   # where to save the model (can be a file or file-like object)                  \n",
    "                  opset_version=11,          # the ONNX version to export the model to                  \n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output']  # the model's output names\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = 'input'\n",
    "output_name = 'output'\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input \n",
    "                  \"D:\\\\super_resolution_2.onnx\",   # where to save the model (can be a file or file-like object)                  \n",
    "                  opset_version=11,          # the ONNX version to export the model to                  \n",
    "                  input_names = [input_name],   # the model's input names\n",
    "                  output_names = [output_name],  # the model's output names\n",
    "                  dynamic_axes= {\n",
    "                        input_name: {0: 'batch_size', 2 : 'in_width', 3: 'int_height'},\n",
    "                        output_name: {0: 'batch_size', 2: 'out_width', 3:'out_height'}}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionNet2(nn.Module):\n",
    "    def __init__(self, upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet2, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x, scale):\n",
    "        print(scale)        \n",
    "        y = F.interpolate(x, scale_factor= 1./float(scale), mode=\"bilinear\")\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "        init.zeros_(self.conv4.bias)  \n",
    "\n",
    "# Create the super-resolution model by using the above model definition.\n",
    "model2 = SuperResolutionNet2(upscale_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_17388/1068336433.py:16: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  y = F.interpolate(x, scale_factor= 1./float(scale), mode=\"bilinear\")\n"
     ]
    }
   ],
   "source": [
    "input_name = 'input'\n",
    "output_name = 'output'\n",
    "torch.onnx.export(model2,               \n",
    "                  (x, 2),                         \n",
    "                  \"D:\\\\super_resolution_3.onnx\",   \n",
    "                  opset_version=11,          \n",
    "                  input_names = [input_name],  \n",
    "                  output_names = [output_name],\n",
    "                  dynamic_axes= {\n",
    "                        input_name: {0: 'batch_size', 2 : 'in_width', 3: 'int_height'},\n",
    "                        output_name: {0: 'batch_size', 2: 'out_width', 3:'out_height'}}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb82d7e5416f6a7e93ad7b4056e8fc801ae41614f9a63a1de00dbc26c70ea266"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('d2l': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
